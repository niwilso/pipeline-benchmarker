{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking with an example pipeline\n",
    "This notebook creates and submits a simple pipeline based on the scripts in `./steps`. Each step in this example pipeline uses the `PipelineBenchmarker` class, with the final step showing how to consolidate and save the whole pipeline benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Environment, Datastore, Dataset, Experiment\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.pipeline.core import Pipeline, PipelineData, PipelineParameter\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.data.data_reference import DataReference\n",
    "from msrest.exceptions import HttpOperationError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setting environment config\n",
    "Prior to running this notebook, please create a `.env` file in this directory, using `.env.example` as reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get configuration and secrets\n",
    "Load in the config and retrieve secrets to access the Azure Machine Learning (AML) workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOB_STORAGE_NAME = os.environ['AML_STORAGE_NAME'] \n",
    "BLOB_STORAGE_KEY = os.environ['AML_STORAGE_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log in through Interactive Loging Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=os.environ[\"TENANT_ID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore the AML workspace from the `config.json` file which can be downloaded through the Azure portal. You may also reference the `config.json.example` file in this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set secrets into the assigned KeyVault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_secrets = [\n",
    "    'AML_STORAGE_NAME',\n",
    "    'AML_STORAGE_KEY',\n",
    "]\n",
    "\n",
    "keyvault = ws.get_default_keyvault()\n",
    "\n",
    "if keyvault is None:\n",
    "    print(\"Keyvault for workspace did not load correctly\", Severity.ERROR)\n",
    "# Replace _ with - to change variable name to acceptable format for Keyvault\n",
    "for key in required_secrets:\n",
    "    value = os.getenv(key)\n",
    "    name = key.replace(\"_\", \"-\")\n",
    "    try:\n",
    "        print(f\"Attempting to set env: \\\"{key}\\\" as secret: \\\"{name}\\\" in the workspace keyvault\")\n",
    "        keyvault.set_secret(name=name, value=value)\n",
    "    except HttpOperationError as err:\n",
    "        print(f\"Issue setting secret in keyvault with name: {name}, Err: {str(err)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up the pipeline environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Set the compute target\n",
    "Create the compute target which will be used to execute the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compute(workspace: Workspace, compute_name: str, vm_size: str, vm_priority: str, min_nodes: int, max_nodes: int,\n",
    "                scale_down: int):\n",
    "    \"\"\"Returns an existing compute or creates a new one.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    workspace: Workspace\n",
    "        AzureML workspace\n",
    "    compute_name: str\n",
    "        Name of the compute\n",
    "    vm_size: str\n",
    "        VM size\n",
    "    vm_priority: str\n",
    "        Low priority or dedicated cluster\n",
    "    min_nodes: int\n",
    "        Minimum number of nodes\n",
    "    max_nodes: int\n",
    "        Maximum number of nodes in the cluster\n",
    "    scale_down: int\n",
    "        Number of seconds to wait before scaling down the cluster\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    compute_target : ComputeTarget\n",
    "        A reference to compute\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if compute_name in workspace.compute_targets:\n",
    "            compute_target = workspace.compute_targets[compute_name]\n",
    "            if compute_target and isinstance(compute_target, AmlCompute):\n",
    "                print(f\"Found existing compute target {compute_name} so using it.\")\n",
    "        else:\n",
    "            compute_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n",
    "                                                                   vm_priority=vm_priority,\n",
    "                                                                   min_nodes=min_nodes,\n",
    "                                                                   max_nodes=max_nodes,\n",
    "                                                                   idle_seconds_before_scaledown=scale_down,\n",
    "                                                                   )\n",
    "\n",
    "            compute_target = ComputeTarget.create(workspace, compute_name, compute_config)\n",
    "            compute_target.wait_for_completion(show_output=True)\n",
    "        return compute_target\n",
    "    except ComputeTargetException as ex_var:\n",
    "        print(f'An error occurred trying to provision compute: {str(ex_var)}')\n",
    "        sys.exit(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set compute target\n",
    "compute_target = get_compute(\n",
    "    workspace=ws,\n",
    "    compute_name=\"benchmark\",\n",
    "    vm_size='STANDARD_D2_V3',\n",
    "    vm_priority='lowpriority', \n",
    "    min_nodes=0,\n",
    "    max_nodes=4,\n",
    "    scale_down=120,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Set up and register Datastore references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blob_datastore(workspace: Workspace, data_store_name: str, storage_name: str, storage_key: str,container_name: str):\n",
    "    \"\"\"Returns a reference to a datastore\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    workspace : Workspace\n",
    "        Existing AzureML Workspace object\n",
    "    data_store_name : string\n",
    "        Data store name\n",
    "    storage_name : string\n",
    "        Blob storage account name\n",
    "    storage_key : string\n",
    "        Blob storage account key\n",
    "    container_name : string\n",
    "        Container name\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    blob_datastore : Datastore\n",
    "        A reference to datastore\n",
    "    \"\"\"\n",
    "    try:\n",
    "        blob_datastore = Datastore.get(workspace, data_store_name)\n",
    "        print(f\"Found Blob Datastore with name: {data_store_name}\")\n",
    "    except HttpOperationError:\n",
    "        blob_datastore = Datastore.register_azure_blob_container(\n",
    "            workspace=workspace,\n",
    "            datastore_name=data_store_name,\n",
    "            account_name=storage_name,  # Storage account name\n",
    "            container_name=container_name,  # Name of Azure blob container\n",
    "            account_key=storage_key)  # Storage account key\n",
    "    print(f\"Registered blob datastore with name: {data_store_name}\")\n",
    "    return blob_datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up datastore reference and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_datastore = get_blob_datastore(workspace=ws,\n",
    "                                    data_store_name=\"sandbox_ds\",\n",
    "                                    storage_name=BLOB_STORAGE_NAME,\n",
    "                                    storage_key=BLOB_STORAGE_KEY,\n",
    "                                    container_name=\"sandbox\")\n",
    "\n",
    "root_dir = DataReference(\n",
    "    datastore=pipeline_datastore,\n",
    "    data_reference_name=\"root_dir\",\n",
    "    mode=\"mount\"\n",
    ")\n",
    "input_dir = \"experiments/input\"\n",
    "output_dir = \"experiments/output\"\n",
    "results_dir = \"experiments/results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Set up the task-specific environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline run configuration \n",
    "run_config = RunConfiguration()\n",
    "run_config.environment.docker.enabled = False\n",
    "run_config.environment.python.user_managed_dependencies = False\n",
    "run_config.environment.python.conda_dependencies = CondaDependencies.create(\n",
    "    conda_packages=[\n",
    "        \"python==3.8.5\"\n",
    "    ],\n",
    "    pip_packages=[\n",
    "        \"numpy==1.18.5\",\n",
    "        \"pandas==1.1.3\",\n",
    "        \"azureml-core==1.22.0\",\n",
    "        \"azureml-dataprep==2.5.0\",\n",
    "        \"azure-storage-blob==12.5.0\",\n",
    "        \"argparse==1.4.0\",\n",
    "        \"vyper-config==0.6.2\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the pipeline\n",
    "Define the steps of the pipeline. In this example pipeline, each step represents a particular Python script in `./steps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_dir = \"../../\"\n",
    "\n",
    "data_prep_step = PythonScriptStep(\n",
    "    script_name=\"mlops/example_pipeline/steps/prepare_data.py\",\n",
    "    source_directory=steps_dir,\n",
    "    arguments=[\n",
    "        \"--root_dir\",\n",
    "        root_dir,\n",
    "        \"--raw_dir\",\n",
    "        input_dir,\n",
    "        \"--prepared_dir\",\n",
    "        output_dir,\n",
    "    ],\n",
    "    inputs=[root_dir],\n",
    "    outputs=[],\n",
    "    compute_target=compute_target,\n",
    "    runconfig=run_config,\n",
    "    allow_reuse=False,\n",
    ")\n",
    "\n",
    "data_process_step = PythonScriptStep(\n",
    "    script_name=\"mlops/example_pipeline/steps/process_data.py\",\n",
    "    source_directory=steps_dir,\n",
    "    arguments=[\n",
    "        \"--root_dir\",\n",
    "        root_dir,\n",
    "        \"--prepared_dir\",\n",
    "        output_dir,\n",
    "        \"--results_dir\",\n",
    "        results_dir,\n",
    "    ],\n",
    "    inputs=[root_dir],\n",
    "    outputs=[],\n",
    "    compute_target=compute_target,\n",
    "    runconfig=run_config,\n",
    "    allow_reuse=False,\n",
    ")\n",
    "\n",
    "benchmark_step = PythonScriptStep(\n",
    "    script_name=\"mlops/example_pipeline/steps/generate_benchmark_report.py\",\n",
    "    source_directory=steps_dir,\n",
    "    arguments=[\"--root_dir\", root_dir],\n",
    "    inputs=[root_dir],\n",
    "    outputs=[],\n",
    "    compute_target=compute_target,\n",
    "    runconfig=run_config,\n",
    "    allow_reuse=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order the steps and build the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for certain steps to run before starting another\n",
    "data_process_step.run_after(data_prep_step)\n",
    "benchmark_step.run_after(data_process_step)\n",
    "\n",
    "# Build the pipeline\n",
    "list_of_steps = [data_prep_step, data_process_step, benchmark_step]\n",
    "example_pipeline = Pipeline(workspace=ws, steps=[list_of_steps])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Publish and run the pipeline\n",
    "Let's first publish the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the pipeline is consistent \n",
    "example_pipeline.validate()\n",
    "\n",
    "# Publish pipeline\n",
    "published_pipeline = example_pipeline.publish(\n",
    "    name = \"example-pipeline\",\n",
    "    description = \"Pipeline to demonstrate the PipelineBenchmarker class\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that it is published, let's submit and run the example pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the pipeline\n",
    "pipeline_run = Experiment(ws, 'example-pipeline').submit(example_pipeline)\n",
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Viewing benchmarks\n",
    "Now that the pipeline has run, the benchmarking results have been saved into the output of the experiment (pipeline run) in the Azure Machine Learning portal.\n",
    "\n",
    "Benchmarking results have also been written to the mounted blob storage. `/pipeline_benchmarks/benchmarks.csv` contains a record of all the pipeline runs. More detail for each individual run is stored in `pipeline_benchmarks/individual_runs/benchmark_<run ID here>.json`.\n",
    "\n",
    "See the documentation in `../../docs` for more details and example output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
